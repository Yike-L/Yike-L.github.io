@article{FAN2021501,
title = {Detection of scene-irrelevant head movements via eye-head coordination information},
journal = {Virtual Reality & Intelligent Hardware},
volume = {3},
number = {6},
pages = {501-514},
year = {2021},
issn = {2096-5796},
doi = {https://doi.org/10.1016/j.vrih.2021.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S2096579621000917},
author = {Xiaoxiong Fan and Yun Cai and Yufei Yang and Tianxing Xu and Yike Li and Songhai Zhang and Fanglue Zhang},
keywords = {Virtual reality, Human-centered computing, Human-computer interaction (HCI), Interaction paradigms, HCI design and evaluation methods, User models},
abstract = {Background
Accurate motion tracking in head-mounted displays (HMDs) has been widely used in immersive VR interaction technologies. However, tracking the head motion of users at all times is not always desirable. During a session of HMD usage, users may make scene-irrelevant head rotations, such as adjusting the head position to avoid neck pain or responding to distractions from the physical world. To the best of our knowledge, this is the first study that addresses the problem of scene-irrelevant head movements.
Methods
We trained a classifier to detect scene-irrelevant motions using temporal eyehead-coordinated information sequences. To investigate the usefulness of the detection results, we propose a technique to suspend motion tracking in HMDs where scene-irrelevant motions are detected.
Results
/Conclusions Experimental results demonstrate that the scene-relevancy of movements can be detected using eye-head coordination information, and that ignoring scene-irrelevant head motions in HMDs improves user continuity without increasing sickness or breaking immersion.}
}